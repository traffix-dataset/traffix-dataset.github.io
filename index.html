<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
    <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
    <meta property="og:url" content="URL OF THE WEBSITE"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>TraffiX - V2X dataset</title>
    <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-4 publication-title">TraffiX - A V2X Dataset for Multi-Modal Cooperative 3D
                        Object Detection of Traffic Participants Using Onboard and Roadside Sensors</h1>
                    <!-- <div class="is-size-5 publication-authors">
                      Paper authors
                      <span class="author-block">
                        <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">First Author</a><sup>*</sup>,</span>
                        <span class="author-block">
                          <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
                          <span class="author-block">
                            <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                          </span>
                          </div> -->

                    <!-- <div class="is-size-5 publication-authors">
                      <span class="author-block">Institution Name<br>Conferance name and year</span>
                      <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                    </div> -->

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- <span class="link-block">
                              <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                              class="external-link button is-normal is-rounded is-dark">
                                <span class="icon">
                                <i class="fas fa-file-pdf"></i>
                                </span>
                                <span>Paper</span>
                              </a>
                            </span> -->

                            <!-- Supplementary PDF link -->
                            <!-- <span class="link-block">
                              <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                              class="external-link button is-normal is-rounded is-dark">
                              <span class="icon">
                                <i class="fas fa-file-pdf"></i>
                              </span>
                              <span>Supplementary</span>
                              </a>
                            </span> -->

                            <!-- Github link -->
                            <span class="link-block">
                    <a href="https://github.com/traffix-dataset/traffix-dev-kit" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Development Kit</span>
                    </a>
                  </span>

                            <!-- Github link -->
                            <span class="link-block">
                    <a href="https://github.com/traffix-dataset/coopdet3d" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Model</span>
                    </a>
                  </span>

                            <!-- Github link -->
                            <span class="link-block">
                    <a href="https://github.com/traffix-dataset/proanno" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>ProAnno</span>
                    </a>
                  </span>

                            <!-- Dataset link -->
                            <span class="link-block">
                    <a href="https://syncandshare.lrz.de/getlink/fi4gZzFh8BUn6Sw4ZC8u49/traffix-1.0" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-database"></i>
                    </span>
                    <span>Dataset</span>
                    </a>
                  </span>

                            <!-- ArXiv abstract Link -->
                            <!-- <span class="link-block">
                              <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                              class="external-link button is-normal is-rounded is-dark">
                              <span class="icon">
                                <i class="ai ai-arxiv"></i>
                              </span>
                              <span>arXiv</span>
                              </a>
                            </span> -->
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
<!--            <h2 class="title is-3">Dataset Visualization</h2>-->
            <div id="results-carousel" class="carousel results-carousel">
                <div class="item item-video5">
                    <video poster="" id="video5" autoplay controls muted loop height="100%">
                        <source src="static/videos/drive_15_labels_visualization_small.mp4"
                                type="video/mp4">
                    </video>
                </div>
                <div class="item item-video6">
                    <video poster="" id="video6" autoplay controls muted loop height="100%">
                        <source src="static/videos/drive_22_labels_visualization_small.mp4"
                                type="video/mp4">
                    </video>
                </div>
                <div class="item item-video7">
                    <video poster="" id="video7" autoplay controls muted loop height="100%">
                        <source src="static/videos/drive_41_labels_visualization_small.mp4"
                                type="video/mp4">
                    </video>
                </div>
                <div class="item item-video8">
                    <video poster="" id="video8" autoplay controls muted loop height="100%">
                        <source src="static/videos/drive_42_labels_visualization_small.mp4"
                                type="video/mp4">
                    </video>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Overview  -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Overview</h2>
                <div class="content">
                    <strong>TraffiX</strong> is the first high-quality real-world <strong>V2X dataset</strong> for the
                    cooperative 3D object detection and tracking task in autonomous driving.<br><br>
                    It contains:
                    <ul>
                        <li>data collected by <strong>9 sensors</strong> simultaneously from onboard and roadside
                            sensors.
                        </li>
                        <li><strong>1,600</strong> labeled point clouds and <strong>4,000</strong> labeled images.</li>
                        <li><strong>25k</strong> 3D bounding boxes with track IDs.</li>
                        <li>Challenging scenarios: near-miss and <strong>traffic violation events</strong>, overtaking
                            and U-turn maneuvers.
                        </li>
                        <li><strong>HD maps</strong> of the driving domains.</li>
                        <li>Labels in <strong>OpenLABEL</strong> standard.</li>
                        <li>A <strong>dev kit</strong> to load, preprocess, visualize, convert labels, and to evaluate
                            perception methods.
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End overview -->

<!-- Sensor setup  -->
<section class="section hero">
    <div class="container is-max-desktop">
        <div class="columns">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Sensor Setup</h2>
                <div class="content is-align-content-start">
                    On the <strong>infrastructure</strong>, the following roadside sensors were used: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <ul>
                        <li>1x <strong>Ouster</strong> LiDAR OS1-64 (generation 2), 64 vertical layers, 360° FOV, <br>below
                            horizon configuration, 10 cm accuracy @120 m range
                        </li>
                        <li>4x <strong>Basler</strong> ace acA1920-50gc, 1920×1200, Sony IMX174 with 8 mm lenses</li>
                    </ul>
                    <br>On the <strong>vehicle</strong>, the following onboard sensors were used:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <ul>
                        <li>1x <strong>Robosense</strong> RS-LiDAR-32, 32 vert. layers, 360° FOV, 3 cm accuracy @200 m
                            range
                        </li>
                        <li>1x <strong>Basler</strong> ace acA1920-50gc, 1920×1200, Sony IMX174 with 16 mm lens</li>
                        <li>1x <strong>Emlid</strong> Reach RS2+ multi-band RTK GNSS receiver</li>
                        <li>1x <strong>XSENS</strong> MTi-30-2A8G4 IMU</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End sensor setup -->

<!-- infrastructure sensors -->
<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <div class="item">
                <img src="static/images/infrastructure_sensors.jpg" alt="infrastructure_sensors"/>
                <h2 class="subtitle has-text-centered">
                    Visualization of roadside sensors used to record the TraffiX V2X Cooperative Dataset from
                    infrastructure perspective.
                </h2>
            </div>
        </div>
    </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Cooperative perception offers several benefits for enhancing the capabilities of autonomous
                        vehicles and improving road safety. Using roadside sensors in addition to onboard sensors
                        increases reliability and extends the sensor range. They offer a higher situational awareness
                        for automated vehicles and prevent occlusions. We propose CoopDet3D, a cooperative multi-modal
                        fusion model, and TraffiX, a V2X dataset, for the cooperative 3D object detection and tracking
                        task. Our dataset contains 1,600 labeled point clouds and 4,000 labeled images from five
                        roadside and four onboard sensors. It includes 50k 3D boxes with track IDs and precise GPS and
                        IMU data. We labeled eight categories and covered occlusion scenarios with challenging driving
                        maneuvers, like traffic violations, near-miss events, overtaking, and U-turns. Through multiple
                        experiments, we show that our CoopDet3D camera-LiDAR fusion model achieves an increase of +14.36
                        3D mAP compared to a vehicle camera-LiDAR fusion model. Finally, we make our model, dataset,
                        labeling tool, and development kit publicly available to advance in connected and automated
                        driving.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<!--<section class="hero is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <div id="results-carousel" class="carousel results-carousel">-->
<!--       <div class="item">-->
<!--        &lt;!&ndash; Your image here &ndash;&gt;-->
<!--        <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>-->
<!--        <h2 class="subtitle has-text-centered">-->
<!--          First image description.-->
<!--        </h2>-->
<!--      </div>-->
<!--      <div class="item">-->
<!--        &lt;!&ndash; Your image here &ndash;&gt;-->
<!--        <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>-->
<!--        <h2 class="subtitle has-text-centered">-->
<!--          Second image description.-->
<!--        </h2>-->
<!--      </div>-->
<!--      <div class="item">-->
<!--        &lt;!&ndash; Your image here &ndash;&gt;-->
<!--        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>-->
<!--        <h2 class="subtitle has-text-centered">-->
<!--         Third image description.-->
<!--       </h2>-->
<!--     </div>-->
<!--     <div class="item">-->
<!--      &lt;!&ndash; Your image here &ndash;&gt;-->
<!--      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>-->
<!--      <h2 class="subtitle has-text-centered">-->
<!--        Fourth image description.-->
<!--      </h2>-->
<!--    </div>-->
<!--  </div>-->
<!--</div>-->
<!--</div>-->
<!--</section>-->
<!-- End image carousel -->


<!-- Youtube video -->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      &lt;!&ndash; Paper video. &ndash;&gt;-->
<!--      <h2 class="title is-3">Video Presentation</h2>-->
<!--      <div class="columns is-centered has-text-centered">-->
<!--        <div class="column is-four-fifths">-->
<!--          -->
<!--          <div class="publication-video">-->
<!--            &lt;!&ndash; Youtube embed code here &ndash;&gt;-->
<!--            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
<!--          </div>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->
<!-- End youtube video -->



<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>BibTex Code Here</code></pre>
  </div>
</section> -->
<!--End BibTex citation -->


<!--  <footer class="footer">-->
<!--  <div class="container">-->
<!--    <div class="columns is-centered">-->
<!--      <div class="column is-8">-->
<!--        <div class="content">-->
<!--          <p>-->
<!--            Credits to <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"> <strong>Academic Project Page</strong></a>.-->
<!--          </p>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</footer>-->

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

</body>
</html>
